base_model:
    type: Llama
    path: /netcache/huggingface/llama2_7b/
    torch_dtype: auto
    tokenizer_mode: fast
quant:
    method: smoothquant
    skip_layers: [ lm_head ]
    seqlen: 2048
    device: cuda
    weight:
      wbit: 8
      abit: 8
      offload: cpu
      block_sequential: True
      layer_sequential: True
      w_groupsize: 128 
      w_qtype: per_channel
      a_qtype: per_token
      alpha: 0.85
      quant_out: False
    data:
      name: c4
      split: train
      nsamples: 128       
      seqlen: 2048
      download: False
      path: /netcache/huggingface/c4_local/c4-train.00000-of-01024.json.gz
      batch_size: 32
      seed: 42
      
eval:
    # 评测任务类型
    tasks: Commonsense_Reasoning

    # 评测数据集 
    datasets: [winogrande, hellaswag, arc_easy, arc_challenge]
    # datasets: [commonsense_qa, piqa, social_iqa]

    download: False
    path: /netcache/huggingface/c4_local/c4-validation.00000-of-00008.json.gz,
    seq_len: 2048
    batch_size: 32
    num_fewshot: 5
    nsamples: all
    device: cuda
    seqlen: 2048

save: /netcache/zcx2/compress_models/llama2_7b/llama2_7b_smoothquant_w8a8/
